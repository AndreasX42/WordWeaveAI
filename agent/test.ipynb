{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Claude response: Yes, I can!\n",
      "Full response structure: {\n",
      "  \"ResponseMetadata\": {\n",
      "    \"RequestId\": \"5611c473-50a8-45ba-a351-5f429849c37c\",\n",
      "    \"HTTPStatusCode\": 200,\n",
      "    \"HTTPHeaders\": {\n",
      "      \"date\": \"Tue, 01 Jul 2025 13:18:10 GMT\",\n",
      "      \"content-type\": \"application/json\",\n",
      "      \"content-length\": \"302\",\n",
      "      \"connection\": \"keep-alive\",\n",
      "      \"x-amzn-requestid\": \"5611c473-50a8-45ba-a351-5f429849c37c\"\n",
      "    },\n",
      "    \"RetryAttempts\": 0\n",
      "  },\n",
      "  \"output\": {\n",
      "    \"message\": {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": \"Yes, I can!\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"stopReason\": \"end_turn\",\n",
      "  \"usage\": {\n",
      "    \"inputTokens\": 19,\n",
      "    \"outputTokens\": 8,\n",
      "    \"totalTokens\": 27,\n",
      "    \"cacheReadInputTokens\": 0,\n",
      "    \"cacheWriteInputTokens\": 0\n",
      "  },\n",
      "  \"metrics\": {\n",
      "    \"latencyMs\": 1047\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test AWS Bedrock Claude Sonnet 4 Access\n",
    "import boto3\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "response = bedrock.converse(\n",
    "    modelId=\"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                {\"text\": \"Hello! Can you respond with exactly 3 words?\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_text = response['output']['message']['content'][0]['text']\n",
    "print(f\"✅ Claude response: {response_text}\")\n",
    "print(f\"Full response structure: {json.dumps(response, indent=2, default=str)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Instructor test failed: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "Make sure you have instructor[bedrock] installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import instructor\n",
    "    from instructor import Mode\n",
    "    \n",
    "    # Create Instructor client (same as your constants.py)\n",
    "    bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "    \n",
    "    instructor_client = instructor.from_bedrock(\n",
    "        client=bedrock_client,\n",
    "        mode=Mode.BEDROCK_TOOLS,\n",
    "        temperature=0.2,\n",
    "    )\n",
    "    \n",
    "    # Define a test schema (similar to your vocab tools)\n",
    "    class WordAnalysis(BaseModel):\n",
    "        word: str\n",
    "        language: str\n",
    "        part_of_speech: str\n",
    "        definition: str\n",
    "    \n",
    "    # Test structured output\n",
    "    result = instructor_client.create(\n",
    "        model=\"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "        response_model=WordAnalysis,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a linguistic specialist.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Analyze the Spanish word 'casa' and provide structured output.\"}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Instructor integration works!\")\n",
    "    print(f\"Structured result: {result}\")\n",
    "    print(f\"Type: {type(result)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Instructor test failed: {e}\")\n",
    "    print(\"Make sure you have instructor[bedrock] installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Test your actual vocab processor integration\n",
    "print(\"\\n🔍 Testing your vocab processor setup...\")\n",
    "\n",
    "try:\n",
    "    # Import your constants to test the actual integration\n",
    "    import sys\n",
    "    sys.path.append('/Users/andreaspangerl/Desktop/courses/wordweave/agent')\n",
    "    \n",
    "    from vocab_processor.constants import LLMVariant, get_llm_client\n",
    "    from vocab_processor.tools.base_tool import create_llm_response, SystemMessages\n",
    "    \n",
    "    # Test the actual enum and function you built\n",
    "    claude_client = get_llm_client(LLMVariant.CLAUDE4S)\n",
    "    print(f\"✅ LLMVariant.CLAUDE4S client loaded: {type(claude_client)}\")\n",
    "    \n",
    "    # Test with your actual create_llm_response function\n",
    "    class TestSchema(BaseModel):\n",
    "        spanish_word: str\n",
    "        english_translation: str\n",
    "        example_sentence: str\n",
    "    \n",
    "    result = await create_llm_response(\n",
    "        response_model=TestSchema,\n",
    "        user_prompt=\"Translate 'perro' to English and give an example sentence in Spanish.\",\n",
    "        system_message=SystemMessages.LINGUISTIC_SPECIALIST,\n",
    "        llm_provider=LLMVariant.CLAUDE4S\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Your vocab processor Claude integration works!\")\n",
    "    print(f\"Result: {result}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Vocab processor test failed: {e}\")\n",
    "    print(\"This might be expected if running outside your project environment.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instructor import from_openai, Mode\n",
    "from openai import AsyncOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "os.environ[\"OPENAI_LOG\"] = \"debug\"   # must be set before the first client is built\n",
    "\n",
    "from vocab_processor.schemas.spanish_conj_model import SpanishVerbConjugation\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AsyncOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), max_retries=3)\n",
    "instructor_llm = from_openai(client=client, model=\"gpt-4o-mini\", temperature=0.2, mode=Mode.JSON)\n",
    "\n",
    "\n",
    "\n",
    "# Define hook functions\n",
    "def log_kwargs(**kwargs):\n",
    "    print(f\"Function called with kwargs: {kwargs}\")\n",
    "\n",
    "\n",
    "def log_exception(exception: Exception):\n",
    "    print(f\"An exception occurred: {str(exception)}\")\n",
    "\n",
    "    \n",
    "instructor_llm.on(\"completion:kwargs\", log_kwargs)\n",
    "instructor_llm.on(\"completion:error\", log_exception)\n",
    "\n",
    "# x = await instructor_llm.create(\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are an expert Spanish linguist. \"\n",
    "#                     \"Return ONLY valid JSON matching the schema and do it fast.\"},\n",
    "#         {\"role\": \"user\", \"content\": f\"Conjugate the verb 'comprar'.\"}\n",
    "#     ],\n",
    "#     response_model=SpanishVerbConjugation,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(x.model_dump(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from vocab_processor.tools.media_tool import fetch_photos\n",
    "from vocab_processor.schemas.visual_model import Media\n",
    "load_dotenv()\n",
    "from pydantic import BaseModel\n",
    "from pydantic import Field\n",
    "\n",
    "def get_media(source_word: str, target_word: str, source_language: str, target_language: str) -> Media:\n",
    "    \"\"\"\n",
    "    Get the most memorable photo for a vocabulary word.\n",
    "    Steps:\n",
    "    1. Translate word to English with descriptors\n",
    "    2. Fetch Pexels photos\n",
    "    3. Ask LLM to choose the best one\n",
    "    \"\"\"\n",
    "\n",
    "    class Criteria(BaseModel):\n",
    "        query: str = Field(description=\"English search query plus two descriptive synonyms to find the most relevant photos in Pexels\")\n",
    "\n",
    "    try:\n",
    "        # translate to english and get criteria\n",
    "        translation_and_choice_prompt = f\"\"\"\n",
    "        Given the {source_language} word '{source_word}', respond with:\n",
    "        1. `query` – an English search query plus a few descriptive synonyms to find the most relevant photos in Pexels.\n",
    "\n",
    "        Respond in the JSON format provided.\n",
    "        \"\"\"\n",
    "        result = instructor_llm.create(response_model=Criteria, messages=[{\"role\": \"user\", \"content\": translation_and_choice_prompt}])\n",
    "\n",
    "\n",
    "        # fetch three photos\n",
    "        photos = fetch_photos(result.query, per_page=15)\n",
    "\n",
    "        print(photos)\n",
    "\n",
    "\n",
    "        # choose the best photo\n",
    "        rank_prompt = f\"\"\"Find the most adquate photo for the following criteria that depicts best the {source_language} word '{source_word}' that makes it easy to remember the {target_language} word '{target_word}'.\n",
    "\n",
    "        Photos:\n",
    "        {[p.model_dump() for p in photos]}\n",
    "\n",
    "        Respond only in the JSON format provided.\n",
    "        \"\"\"\n",
    "\n",
    "        print(rank_prompt)\n",
    "\n",
    "        result = instructor_llm.create(\n",
    "            response_model=Media,\n",
    "            messages=[{\"role\": \"user\", \"content\": rank_prompt}],\n",
    "        )\n",
    "\n",
    "        print(result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error generating visual media: {e!s}\"\n",
    "\n",
    "get_media(source_word=\"Kaputze\", target_word=\"gorra\", source_language=\"Deutsch\", target_language=\"Spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from my_agent.tools.pronounciation_tool import LANGUAGE_VOICES\n",
    "from elevenlabs import VoiceSettings, play, save\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "LANGUAGE_VOICES = {\n",
    "    \"English\": \"EXAVITQu4vr4xnSDxMaL\",  # Bella - English\n",
    "    \"Spanish\": \"94zOad0g7T7K4oa7zhDq\",  # Mauricio\n",
    "    \"German\": \"XrExE9yKIg1WjnnlVkGX\",   # Matilda - Multi-language\n",
    "}\n",
    "\n",
    "target_language = \"Spanish\"\n",
    "voice_id = LANGUAGE_VOICES.get(target_language, LANGUAGE_VOICES[\"English\"])\n",
    "        \n",
    "client = ElevenLabs()\n",
    "\n",
    "audio = client.text_to_speech.convert(\n",
    "    text=\"Hello\",\n",
    "    voice_id=voice_id,\n",
    "    language_code=\"es\",\n",
    "    model_id=\"eleven_flash_v2_5\",\n",
    "    output_format=\"mp3_44100_128\",\n",
    "    voice_settings=VoiceSettings(\n",
    "        speed=0.7,\n",
    "        stability=0.3,\n",
    "        similarity_boost=0.2,\n",
    "        style=0.2,\n",
    "        use_speaker_boost=True\n",
    "    )\n",
    ")\n",
    "\n",
    "# play(audio=audio)\n",
    "save(audio, \"quisquilloso.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
